<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How to Translate a Math PDF (AI-Assisted)</title>
    <style>
        /* Basic styling for readability */
        body { font-family: sans-serif; line-height: 1.6; margin: 2em; max-width: 900px; margin-left: auto; margin-right: auto; }
        h1, h2, h3, h4 { margin-top: 1.5em; color: #333; }
        h1 { border-bottom: 2px solid #eee; padding-bottom: 0.3em;}
        pre { background-color: #f8f8f8; padding: 1em; border: 1px solid #ddd; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word; font-size: 0.9em; border-radius: 4px; }
        code { font-family: monospace; background-color: #f0f0f0; padding: 0.2em 0.4em; border-radius: 3px;}
        ul, ol { margin-left: 1.5em; }
        li { margin-bottom: 0.5em; }
        a { color: #007bff; text-decoration: none; }
        a:hover { text-decoration: underline; }
        /* Style to visually separate AI's explanation */
        .ai-explanation { border-left: 4px solid #4285F4; /* Google blue */ padding-left: 1em; margin-top: 1.5em; margin-bottom: 1.5em; background-color: #f9f9f9; border-radius: 4px; padding: 1em; }
        .requirements ul li strong { display: inline-block; min-width: 150px; } /* Align requirement titles */
        .warning { color: #dc3545; font-weight: bold; }
        .note { font-style: italic; color: #555; }
    </style>
</head>
<body>

<h1>How to Translate a Math PDF (AI-Assisted)</h1>

<p>Modern multimodal AI models can take a math paper in a non-English language (provided as a PDF) and output a translation directly in LaTeX. This guide explains how to use a Python script that leverages multiple AI providers (Anthropic Claude, OpenAI GPT, Google Gemini) in a robust "tournament" system to achieve this.</p>

<p><span class="warning">Disclaimer:</span> AI translations, especially for complex technical documents, carry risks of hallucination or error. This guide and the accompanying script reflect capabilities as of mid-2024; they may require updates as APIs and models evolve. Always carefully review the generated LaTeX output. <span class="warning">Furthermore, be mindful of copyright restrictions when translating and distributing academic papers. Some AI models may refuse to process copyrighted material; this script tries multiple models, which might help if one refuses, but ensure you have the necessary rights to translate and use the material.</span></p>

<p>The core translation ability resides within the AI models themselves. This script provides scaffolding to overcome common challenges:</p>
<ul>
    <li><strong>Output Length Limits:</strong> AIs often struggle to generate LaTeX for very long papers in a single API call (handled by page-by-page processing).</li>
    <li><strong>API Reliability/Failures:</strong> Individual API calls can fail. The script tries a queue of different models and retries them for robustness.</li>
    <li><strong>Model-Specific Weaknesses:</strong> Some models might be better at certain content types. Trying multiple models increases the chance of success.</li>
    <li><strong>Consistency:</strong> Maintaining consistent LaTeX formatting and translation style across many pages can be difficult (context from previous pages helps).</li>
    <li><strong>Compilation Errors:</strong> AI-generated LaTeX might contain errors. The script performs compilation checks after each page.</li>
</ul>

<p>We divide this guide into two main situations.</p>

<h2>Situation 1 (Easiest): Translating Short Papers (e.g., < 20 pages)</h2>

<p>For short papers, direct translation via a chat interface of a capable multimodal AI (like Google AI Studio, Anthropic's Console, or OpenAI's ChatGPT with vision) is often sufficient.</p>
<ol>
    <li><strong>Method:</strong> Upload the PDF directly into the chat interface.</li>
    <li><strong>Prompt:</strong> Use a detailed prompt like:
        <pre><code>Please translate the uploaded non-English math document into English LaTeX code. Preserve all mathematical formulas, equations, and environments accurately using standard LaTeX (amsmath, amssymb, etc.). Generate a complete LaTeX document, including a suitable preamble (documentclass, common packages like graphicx, amsthm, hyperref), metadata (title, author if visible), and the translated content.</code></pre>
    </li>
    <li><strong>Process:</strong> Copy the AI's generated LaTeX, paste it into a LaTeX editor (e.g., Overleaf, VS Code with LaTeX Workshop), compile, and meticulously review the resulting PDF for correctness and formatting.</li>
</ol>

<h2>Situation 2: Translation for Longer Papers via the Multi-Model AI Script</h2>

<p>For longer papers, the provided Python script (`translator.py`) automates a page-by-page translation process using a queue of AI models (Claude, Gemini, GPT), with fallback mechanisms for pages that fail translation attempts across all available models.</p>

<p>The script workflow:</p>
<ol>
    <li>Reads processing state (if resuming).</li>
    <li>Iterates through PDF pages, converting each to an image.</li>
    <li>For each page image, it attempts translation using a **tournament of models**:
        <ul>
            <li>Starts with the preferred model (or the first in the default queue).</li>
            <li>If a model fails (API error, blocked response, bad output), it tries the *next* model in the queue.</li>
            <li>Each model is retried a few times (`MAX_RETRIES_PER_MODEL`) within its turn.</li>
            <li>If the entire queue is exhausted, it cycles through the queue again up to `MAX_MODEL_CYCLES` times.</li>
            <li>If a model successfully returns LaTeX, the script attempts to compile the document up to that page.</li>
            <li>If compilation fails *after* a successful translation, or if *all models fail* after all cycles/retries, it inserts a placeholder into the LaTeX document, saves the original page image to `failed_pages/` for manual review, and then continues with the next page.</li>
        </ul>
    </li>
    <li>Appends the successful LaTeX (or placeholder) for the current page to the cumulative document.</li>
    <li>Saves the state (`state.json`), model usage stats (`model_stats.json`), and the last known good `.tex`/`.pdf` files after each successfully processed page (or page with a placeholder).</li>
    <li>At the end, generates a LaTeX report summarizing model performance and failures, compiles it, and merges it with the main translated PDF.</li>
</ol>

<p>We provide the <a href="translator.py" download>example Python script</a>.
<!-- Make sure translator.py is in the same directory -->
To use this script, you need API keys for the AI providers you wish to use and a correctly configured Python environment.</p>

<p>Here's a more detailed explanation:</p>

<div class="ai-explanation"> <!-- Start of AI Explanation -->
    <h3>How to Use the Python Script (translator.py)</h3>

    <h4>1. Requirements:</h4>
    <ul class="requirements">
        <li><strong>Python:</strong> Version 3.x recommended. Use a virtual environment (`venv`).</li>
        <li><strong>Python Packages:</strong> Install via pip:
            <pre><code>pip install google-generativeai anthropic openai pdf2image Pillow pypdf</code></pre>
        </li>
        <li><strong>Poppler:</strong> Required by `pdf2image`. Install system-wide (e.g., `brew install poppler`, `sudo apt-get install poppler-utils`). Ensure it's in your PATH. <span class="warning">Installation issues are common! Check logs if image conversion fails.</span></li>
        <li><strong>LaTeX Distribution:</strong> A working installation (TeX Live, MiKTeX) is **required**. The `pdflatex` command must be runnable from your terminal.</li>
        <li><strong>API Keys:</strong> You need API keys for the providers of the models you intend to use. Set them as environment variables:
            <ul>
                <li><code>ANTHROPIC_API_KEY</code> (for Claude models)</li>
                <li><code>OPENAI_API_KEY</code> (for GPT models)</li>
                <li><code>GOOGLE_API_KEY</code> (for Gemini models)</li>
            </ul>
             Get keys from their respective websites (Anthropic Console, OpenAI Platform, Google AI Studio). The script will skip models from providers whose keys are not found/set.
        </li>
    </ul>

    <h4>2. Configuration (Optional):</h4>
    <ul>
        <li><strong>Model Configs:</strong> Edit the `get_model_configs()` function within `translator.py` to add or update model details. Use `--list-models` to see current options.</li>
        <li><strong>Default Model Queue:</strong> Change the `DEFAULT_MODEL_QUEUE` list in the script to modify the default order in which models are tried.</li>
        <li><strong>Working Directory:</strong> Outputs go to a hardcoded directory named `latex_processing` created in the same directory where the script is run. <span class="note">(This version does not have a `--working-dir` flag).</span></li>
        <li><strong>Retries/Cycles:</strong> Adjust `MAX_RETRIES_PER_MODEL` and `MAX_MODEL_CYCLES` constants in the script for more or less aggressive attempts per page.</li>
    </ul>


    <h4>3. Running the Script:</h4>
    <p>Open your terminal/command prompt in the directory containing `translator.py`.</p>
    <p><strong>Basic Command (using default model queue):</strong></p>
    <pre><code>python translator.py [path/to/your/input.pdf]</code></pre>
    <p><strong>Command with a Preferred Starting Model:</strong></p>
    <pre><code>python translator.py [path/to/your/input.pdf] --model MODEL_KEY</code></pre>
    <ul>
        <li>The <strong>Input PDF Path</strong> is the first (optional) argument. If omitted, it defaults to `input.pdf` in the script's directory.</li>
        <li>The <code>--model</code> flag specifies which AI model you want to try *first*. The script will still fall back to other models in the `DEFAULT_MODEL_QUEUE` if the preferred one fails.</li>
    </ul>

    <p><strong>Example Commands:</strong></p>
    <pre><code class="language-bash"># Translate my_paper.pdf using the default model queue
python translator.py my_paper.pdf

# Translate input.pdf, trying gemini-2-5-pro-exp *first*, then others in the default queue
python translator.py --model gemini-2-5-pro-exp

# Translate paper_v2.pdf, trying gpt-4o *first*, then others
python translator.py paper_v2.pdf --model gpt-4o</code></pre>

    <p class="note"><em>Use quotes around paths with spaces. You might need <code>python3</code> instead of <code>python</code>.</em></p>

    <h4>4. Command-Line Options (Flags):</h4>
    <ul>
        <li><code>input_pdf</code> (Positional, Optional): Path to the input PDF (defaults to `input.pdf`).</li>
        <li><code>--model MODEL_KEY</code> or <code>-m MODEL_KEY</code>: Specify a preferred model key (e.g., `claude-3-7`, `gpt-4o`, `gemini-2-5-pro-exp`) to try *first* for each page. The script will cycle through the rest of the default queue if this model fails. Use <code>--list-models</code> to see available keys.</li>
        <li><code>--list-models</code> or <code>-l</code>: Display available model keys configured in the script, then exit.</li>
    </ul>

    <h4>5. Available Models (Examples from Script):</h4>
    <p>The script supports multiple AI models configured in `get_model_configs()`. Examples include:</p>
    <ul>
        <li><strong>Claude Models:</strong> claude-3-7 (Sonnet), claude-3-sonnet, claude-3-haiku</li>
        <li><strong>Gemini Models:</strong> gemini-2-5-pro-exp, gemini-2-5-pro-preview, gemini-1-5-pro, gemini-1-5-flash</li>
        <li><strong>OpenAI Models:</strong> gpt-4o, gpt-4o-mini</li>
    </ul>
    <p>Use <code>--list-models</code> to see the complete, up-to-date list of model keys available in your version of the script and the default processing order.</p>

    <h4>6. Output Files (in `./latex_processing` Directory):</h4>
    <ul>
        <li><code>cumulative_good.tex</code>: The latest successfully compiled LaTeX source (including placeholders for failed pages).</li>
        <li><code>cumulative_good.pdf</code>: The PDF generated from `cumulative_good.tex`. Represents the last known good state.</li>
        <li><code>processing.log</code>: Detailed log of the translation process, including model attempts and errors.</li>
        <li><code>state.json</code>: Stores the last completed page number for resuming.</li>
        <li><code>model_stats.json</code>: Tracks which models successfully translated which pages, and records page failures.</li>
        <li><code>latex_aux/</code>: Directory containing auxiliary files from LaTeX compilation (`.log`, `.aux`, `.pdf`, etc.).</li>
        <li><code>failed_pages/</code>: Contains images (`.jpg`) of pages that failed all translation attempts across all models or failed compilation.</li>
        <li><code>*.log</code> (e.g., `compile_fail_page_*.log`, `report_compile.log`, `failed_appendix_compile.log`): Specific logs for compilation failures of main doc or reports.</li>
        <li><code>model_report.tex</code> / <code>failed_pages_appendix.tex</code>: Source files for generated reports.</li>
        <li><code>*_final.pdf</code> / <code>*_final_with_report.pdf</code>: The final output PDF, potentially merged with the performance report and failed page appendix. (Located in the `latex_processing` directory).</li>
        <li><code>current_attempt.tex</code>: Temporary file holding the LaTeX for the page currently being processed and compiled.</li>
    </ul>

    <h4>7. Resuming and Error Handling:</h4>
    <ul>
        <li><strong>Resuming:</strong> Simply run the script again with the same input PDF and preferred model flag (if used). It will read `state.json` and continue from the last successfully completed page.</li>
        <li><strong>Failures:</strong>
            <ul>
                <li>If a model's API call fails or returns unusable content, the script tries the next model in the queue, retrying each model several times and cycling through the queue multiple times.</li>
                <li>If a model returns LaTeX successfully, but that LaTeX causes a compilation error when added, the script treats that page as failed, inserts a placeholder, saves the original page image, and moves to the next page.</li>
                <li>If *all models fail* all retries/cycles for a page, its image is saved in `failed_pages/`, a placeholder is inserted in the LaTeX, and processing continues to the next page.</li>
                <li>Review `processing.log`, `model_stats.json`, and any `compile_fail_*.log` files to understand failures.</li>
                <li>Manually edit `cumulative_good.tex` *after* the script completes to fix translation errors or replace placeholders if desired, then recompile manually.</li>
            </ul>
        </li>
    </ul>


    <h3>Key Features of the Script</h3>
    <ul>
        <li><strong>Multi-Model Tournament:</strong> Leverages a queue of models (Claude, GPT, Gemini) for increased robustness and success rate.</li>
        <li><strong>Robust Retry/Cycle Mechanism:</strong> Retries individual models and cycles through the entire model queue multiple times before giving up on a page.</li>
        <li><strong>Intelligent Fallback:</strong> Inserts placeholders and saves original images for pages that fail all AI attempts or cause compilation errors, ensuring the process continues.</li>
        <li><strong>Configurable Model Preference:</strong> Allows specifying a preferred model to try first via command line.</li>
        <li><strong>Page-by-Page Processing:</strong> Handles long documents by processing one page at a time.</li>
        <li><strong>Image-Based Translation:</strong> Converts PDF pages to images for multimodal AI input.</li>
        <li><strong>Contextual Prompting:</strong> Provides models with context from the previous page's LaTeX output.</li>
        <li><strong>Inline Compilation Checks:</strong> Attempts `pdflatex` compilation after each page is added to catch LaTeX errors early.</li>
        <li><strong>Graceful Failure Handling:</strong> Designed to complete the document even if some pages fail, using placeholders.</li>
        <li><strong>State Management:</strong> Automatically saves and resumes progress using `state.json`.</li>
        <li><strong>Performance Reporting:</strong> Generates statistics (`model_stats.json`) and a final PDF report summarizing model performance and page failures.</li>
        <li><strong>Report Merging:</strong> Automatically merges the performance report and an appendix of failed page images into the final PDF.</li>
        <li><strong>Command-Line Interface:</strong> Flexible control via CLI arguments.</li>
        <li><strong>Detailed Logging:</strong> Records progress, model attempts, and errors to `processing.log`.</li>
    </ul>
</div> <!-- End of ai-explanation div -->

</body>
</html>
