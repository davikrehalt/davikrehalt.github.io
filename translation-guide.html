<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- You might want to link your existing CSS here if you have one -->
    <!-- <link rel="stylesheet" href="assets/css/style.css"> -->
    <title>How to Translate a Math PDF (Jointly written with Gemini 2.5 Pro)</title>
    <style>
        /* Basic styling for readability */
        body { font-family: sans-serif; line-height: 1.6; margin: 2em; }
        h1, h2, h3 { margin-top: 1.5em; }
        pre { background-color: #f4f4f4; padding: 1em; border: 1px solid #ddd; overflow-x: auto; white-space: pre-wrap; /* Wrap long lines */ word-wrap: break-word; /* Break words if needed */ }
        code { font-family: monospace; }
        ul, ol { margin-left: 1.5em; }
        li { margin-bottom: 0.5em; }
        .gemini-explanation { border-left: 4px solid #4285F4; /* Google blue */ padding-left: 1em; margin-top: 1.5em; }
    </style>
</head>
<body>

<h1>How to Translate Math PDFs into LaTeX using AI (Jointly written with Gemini 2.5 Pro)</h1>

<p>Nowadays, my preferred method for reading non-English math papers is to feed them into a multimodal AI model and ask for a translation directly into LaTeX format. I find current AI translations mostly sufficient, and rarely need to refer to the original paper. The speed and readability benefits, for me, often outweigh the risks of AI hallucination or error, though you must always weigh this trade-off yourself. Here I record one (probably far from optimal) way of doing this (we will use Gemini 2.5 Pro by default since it is considered a strong model for math as of April 2025).</p>

<p>The core capability for this task has to exist in the multimodal AI itself for this approach to work. The guide below merely provides scaffolding to overcome the following two common challenges:</p>
<ul>
    <li><strong>Output Length Limits:</strong> AIs often can't generate the entire LaTeX for a long paper in one output, especially via API calls.</li>
    <li><strong>AI Confusion from Input Size:</strong> Processing hundreds of pages of math can sometimes lead to a degradation in translation ability or increased errors.</li>
</ul>

<p>We divide this guide into two main situations.</p>

<h2>Situation 1 (Easiest): Translating Short Papers (e.g., < 20 pages)</h2>

<p>If the paper is short, you can often translate it directly using a chat interface for any capable multimodal AI model (like Google's AI Studio for Gemini).</p>
<ol>
    <li><strong>Method:</strong> Upload the PDF directly into the chat interface.</li>
    <li><strong>Prompt:</strong> Use a prompt like this:
        <pre><code>Please translate the uploaded document into English LaTeX code. Ensure all mathematical formulas and environments are preserved correctly. Generate the complete LaTeX document, including a suitable preamble.</code></pre>
    </li>
    <li><strong>Process:</strong> Copy the AI's generated LaTeX output, paste it into your LaTeX editor (e.g., Overleaf), compile, and carefully review the resulting PDF.</li>
</ol>

<h2>Situation 2: Translation for Longer Papers via an API</h2>

<p>For longer papers, we must divide the paper into manageable chunks for translation. Using the Gemini API, we can write code to automate this process. The philosophy here is that the scaffolding imposed on the AI model should be minimal, so as not to interfere with the AI's own ability to process and translate effectively.</p>

<p>The basic script workflow involves these steps:</p>
<ol>
    <li>Determine how to split the PDF into chunks (e.g., based on logical sections suggested by the AI, or simply using fixed page counts).</li>
    <li>Call the Gemini API for each chunk, sending the relevant pages (potentially as images or extracted text, depending on the chosen API capabilities and complexity) for translation into LaTeX format.</li>
    <li>Combine the resulting LaTeX pieces generated for each chunk into a single, final <code>.tex</code> file.</li>
</ol>

<p>In order for this automated approach to work, you first need to obtain a Gemini API key and set up a Python environment on your computer. Once that's done, you can use the script provided below. Note that I generated all the code presented here with assistance from Gemini.</p>

<p>I'll let Gemini explain how to use the script below:</p>

<div class="gemini-explanation"> <!-- Added a div for potential styling -->
    <h3>How to Use the Python Script</h3>
    <p>(Assuming you have downloaded the <code>pdf_latex_translator.py</code> script)</p>

    <h4>1. Install Libraries:</h4>
    <p>Open your terminal or command prompt and run:</p>
    <pre><code>pip install google-generativeai pypdf python-dotenv</code></pre>

    <h4>2. Set up API Key:</h4>
    <ul>
        <li>Create a file named <code>.env</code> in the same directory as the script.</li>
        <li>Add your Gemini API key to the <code>.env</code> file like this:
            <pre><code>GEMINI_API_KEY=YOUR_API_KEY_HERE</code></pre>
            (Replace <code>YOUR_API_KEY_HERE</code> with your actual key).
        </li>
        <li>Alternatively, you can set <code>GEMINI_API_KEY</code> as an environment variable directly in your operating system.</li>
    </ul>

    <h4>3. Run the Script:</h4>
    <p>Execute the script from your terminal:</p>
    <pre><code>python pdf_latex_translator.py "path/to/your/document.pdf" "path/to/output/translated_document.tex"</code></pre>
    <ul>
        <li>Replace <code>"path/to/your/document.pdf"</code> with the actual path to your input PDF file.</li>
        <li>Replace <code>"path/to/output/translated_document.tex"</code> with the desired path for the output LaTeX file.</li>
    </ul>

    <h4>4. Optional Arguments:</h4>
    <p>You can modify the script's behavior using command-line arguments:</p>
    <ul>
        <li><code>--env path/to/.env</code>: Specify a different path for the <code>.env</code> file if it's not in the same directory.</li>
        <li><code>--chunk_size N</code>: Set the number of pages per chunk if AI chunking fails or is disabled (default is 10).</li>
        <li><code>--disable_ai_chunking</code>: Force the script to use fixed-size chunks instead of trying the experimental AI chunking.</li>
        <li><code>--model model_name</code>: Specify a different Gemini model (e.g., <code>gemini-1.0-pro</code>). The default is typically <code>gemini-1.5-flash</code> which is often suitable for this task. Check Google's documentation for available models and capabilities.</li>
    </ul>

    <h3>Explanation and Key Features of the Script</h3>
    <ul>
        <li><strong>API Key Loading:</strong> Securely loads the API key using <code>python-dotenv</code>.</li>
        <li><strong>PDF Handling:</strong> Uses <code>pypdf</code> to read page count and extract text from specified page ranges, with basic error handling.</li>
        <li><strong>Chunking Strategy:</strong>
            <ul>
                <li>Attempts experimental AI chunking (<code>attempt_ai_chunking</code>) by default, asking Gemini for logical page ranges based on initial content.</li>
                <li>Falls back to reliable fixed-size chunks (<code>generate_fixed_chunk_ranges</code>) if AI chunking fails, returns invalid data, or is explicitly disabled.</li>
            </ul>
        </li>
        <li><strong>Gemini Translation:</strong>
            <ul>
                <li>Constructs specific prompts for each chunk.</li>
                <li>The first chunk's prompt requests the LaTeX preamble and <code>\begin{document}</code>.</li>
                <li>Subsequent chunks' prompts request only the translated body content, preserving math.</li>
                <li>Includes basic safety settings and error handling for API calls.</li>
                <li>Cleans potential markdown fences (e.g., ```latex ... ```) from the response.</li>
            </ul>
        </li>
        <li><strong>Combining Output:</strong> Joins translated parts, ensuring only one <code>\begin{document}</code>...<code>\end{document}</code> pair exists in the final file.</li>
        <li><strong>Error Handling:</strong> Includes error checks for file I/O, PDF reading, and API calls, logging issues and adding error markers in the output <code>.tex</code> file for failed chunks.</li>
        <li><strong>Command-Line Interface:</strong> Uses <code>argparse</code> for easy configuration via command-line arguments.</li>
        <li><strong>Logging:</strong> Provides informative messages during execution.</li>
    </ul>
</div> <!-- End of gemini-explanation div -->

<p>You can download the example Python script discussed above here: <a href="pdf_latex_translator.py" download>pdf_latex_translator.py</a>.</p>
<!-- Make sure pdf_latex_translator.py is in the same directory as this HTML file, or adjust the href path -->

</body>
</html>
