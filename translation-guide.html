<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How to Translate a Math PDF (Co-written with Gemini 2.5 Pro)</title>
    <style>
        /* Basic styling for readability */
        body { font-family: sans-serif; line-height: 1.6; margin: 2em; }
        h1, h2, h3, h4 { margin-top: 1.5em; }
        pre { background-color: #f4f4f4; padding: 1em; border: 1px solid #ddd; overflow-x: auto; white-space: pre-wrap; /* Wrap long lines */ word-wrap: break-word; /* Break words if needed */ }
        code { font-family: monospace; }
        ul, ol { margin-left: 1.5em; }
        li { margin-bottom: 0.5em; }
        /* Style to visually separate Gemini's explanation */
        .gemini-explanation { border-left: 4px solid #4285F4; /* Google blue */ padding-left: 1em; margin-top: 1.5em; margin-bottom: 1.5em;}
    </style>
</head>
<body>

<h1>How to Translate a Math PDF (Co-written with Gemini 2.5 Pro)</h1>

<p>Nowadays, multimodal AI models can take as input a math paper in a non-English language and output a translation directly in LaTeX. Below is a guide on this. Before proceeding, beware that there are always risks of hallucination or error from the AI and from the fact that this guide was written in April 2025 and was suboptimal even when written.</p>

<p>A quick note: for this to work, the core capability for this task has to exist in the multimodal AI itself. The guide below merely provides scaffolding to overcome the following two common challenges:</p>
<ul>
    <li><strong>Output Length Limits:</strong> AIs often can't generate the entire LaTeX for a long paper in one output, especially via API calls.</li>
    <li><strong>AI Confusion from Input Size:</strong> Processing hundreds of pages of math can sometimes lead to a degradation in translation ability or increased errors.</li>
</ul>

<p>We divide this guide into two main situations.</p>

<h2>Situation 1 (Easiest): Translating Short Papers (e.g., < 20 pages)</h2>

<p>If the paper is short, you can often translate it directly using a chat interface for any capable multimodal AI model (like Google's AI Studio for Gemini).</p>
<ol>
    <li><strong>Method:</strong> Upload the PDF directly into the chat interface.</li>
    <li><strong>Prompt:</strong> Use a prompt like this:
        <pre><code>Please translate the uploaded document into English LaTeX code. Ensure all mathematical formulas and environments are preserved correctly. Generate the complete LaTeX document, including a suitable preamble.</code></pre>
    </li>
    <li><strong>Process:</strong> Copy the AI's generated LaTeX output, paste it into your LaTeX editor (e.g., Overleaf), compile, and carefully review the resulting PDF.</li>
</ol>

<h2>Situation 2: Translation for Longer Papers via an API</h2>

<p>For longer papers, we must divide the paper into manageable chunks for translation. Using the Gemini API, it is possible to write code to automate this process. The philosophy here is that the scaffolding imposed on the AI model should be minimal, so as not to interfere with the AI's own ability to process and translate effectively.</p>

<p>The basic script workflow involves these steps:</p>
<ol>
    <li>Determine how to split the PDF into chunks (e.g., based on logical sections suggested by the AI, or simply using fixed page counts).</li>
    <li>Call the Gemini API for each chunk, sending the relevant pages (potentially as images or extracted text, depending on the chosen API capabilities and complexity) for translation into LaTeX format.</li>
    <li>Combine the resulting LaTeX pieces generated for each chunk into a single, final <code>.tex</code> file.</li>
</ol>

<!-- User's corrected paragraph -->
<p>We provide an <a href="pdf_latex_translator.py" download>example script</a> written with Gemini.
<!-- Make sure pdf_latex_translator.py is in the same directory as this HTML file, or adjust the href path -->
In order the use this script, you first need to obtain a Gemini API key and set up a Python environment with the necessary libraries installed. </p>

<p>I'll let Gemini explain in more detail:</p>
        <div class="gemini-explanation"> <!-- Start of Gemini's Explanation -->
    <h3>How to Use the Python Script</h3>
    <p>(Assuming you have downloaded the image-based translator script with compilation checks, let's call it <code>pdf_latex_translator_compile.py</code>)</p>

    <h4>1. Requirements:</h4>
    <ul>
        <li><strong>Python Environment:</strong> A working Python installation (version 3.x recommended). Using a virtual environment (like `venv`) is highly recommended.</li>
        <li>
            <strong>Required Python Packages:</strong> Install these using pip (or pip3):
            <pre><code>pip install google-generativeai pdf2image Pillow pypdf python-dotenv</code></pre>
        </li>
        <li>
            <strong>External Dependency: Poppler:</strong> The `pdf2image` library requires the Poppler PDF rendering library. You must install it separately (see previous instructions). <em>Failure to install Poppler correctly is a common reason for errors.</em>
        </li>
        <li>
            <strong>External Dependency: LaTeX Distribution:</strong> This version of the script **requires a working LaTeX installation** (like TeX Live, MiKTeX) on your system. The command <code>pdflatex</code> must be runnable from your terminal (i.e., in your system's PATH).
        </li>
        <li><strong>Gemini API Key:</strong> Obtain an API key from <a href="https://aistudio.google.com/app/apikey" target="_blank" rel="noopener noreferrer">Google AI Studio</a> and save it securely (e.g., in a <code>.env</code> file or as an environment variable).</li>
    </ul>

    <h4>2. Run the Script:</h4>
    <p>
        To run the script, open your terminal or command prompt. The basic command structure is:
    </p>
    <pre><code>python [script_name.py] [input_pdf_path] [output_tex_path] [options...]</code></pre>
    <p>
        Crucially, the script **requires two positional arguments** that must come first and in this specific order:
    </p>
        <ol>
             <li><strong>Input PDF Path:</strong> The full path to the PDF file you want to translate. This argument does <em>not</em> use a flag like <code>--input</code>.</li>
             <li><strong>Output TeX Path:</strong> The full path where the script should save the generated LaTeX (<code>.tex</code>) file. This argument does <em>not</em> use a flag like <code>--output</code>.</li>
        </ol>
    <p>
        Optional arguments (like <code>--model</code> or <code>--start_page</code>) must come <em>after</em> these first two required paths.
    </p>
    <p><strong>Example Command:</strong></p>
    <pre><code>python pdf_latex_translator_compile.py "My Documents/Research/paper_to_translate.pdf" "My Documents/Output/translated_paper.tex" --start_page 10 --model gemini-1.5-pro-latest</code></pre>
    <ul>
        <li>In this example:
            <ul>
              <li><code>pdf_latex_translator_compile.py</code> is the script name.</li>
              <li><code>"My Documents/Research/paper_to_translate.pdf"</code> is the <strong>required input PDF path</strong>.</li>
              <li><code>"My Documents/Output/translated_paper.tex"</code> is the <strong>required output TeX path</strong>.</li>
              <li><code>--start_page 10</code> and <code>--model gemini-1.5-pro-latest</code> are optional arguments placed after the required paths.</li>
            </ul>
        </li>
        <li>Use quotes around paths if they contain spaces.</li>
        <li><em>Note: You might need to use <code>python3</code> instead of <code>python</code> depending on your system.</em></li>
    </ul>

    <h4>3. Optional Arguments (Flags):</h4>
    <p>Add these flags *after* the required input PDF and output TeX paths to customize behavior:</p>
    <ul>
        <li><code>--env path/to/.env</code>: Specify a different path for your <code>.env</code> file.</li>
        <li>
            <code>--model model_name</code>: Specify a Gemini vision model (default: <code>gemini-2.5-pro-exp-03-25</code>). Consider paid alternatives like <code>gemini-2.5-pro-preview-03-25</code> for higher limits/stability. Check Google's documentation.
        </li>
        <li><code>--start_page N</code>: Start processing from page N (1-based). Useful for resuming.</li>
        <li><code>--chunk_size N</code>: Pages to process before attempting LaTeX compilation (default: 10).</li>
    </ul>

    <h3>Explanation and Key Features of the Script</h3>
    <p>(This section outlines the script's internal logic. Refer to the script's comments for full details.)</p>
    <ul>
        <li><strong>API Key Loading:</strong> Securely loads the Gemini API key.</li>
        <li><strong>PDF Page Handling:</strong> Uses <code>pypdf</code> for page count and <code>pdf2image</code> (requires Poppler) for page-to-image conversion.</li>
        <li><strong>Page-by-Page Image Translation:</strong> Iterates through pages, sending each image to the specified Gemini vision model (defaulting to <code>gemini-2.5-pro-exp-03-25</code>) for LaTeX generation.</li>
        <li><strong>Enhanced Contextual Prompts:</strong> To improve consistency, the script now includes the full LaTeX content generated for the **previous successfully compiled chunk** (typically 10 pages, controlled by <code>--chunk_size</code>) as reference context in the prompt for the current page's translation (limited by <code>--max_context</code> to avoid excessive input size). It instructs the AI to maintain consistency with this context but not repeat it.</li>
        <li><strong>Chunk-Based Compilation Check:</strong> After processing a set number of pages (<code>--chunk_size</code>), the script writes the accumulated LaTeX and attempts compilation using <code>pdflatex</code> (requires LaTeX installed), saving the log.</li>
        <li><strong>Error Handling & Halting on Failure:</strong> Handles API, file, and image conversion errors. **Stops execution** if a LaTeX compilation fails, saving the faulty <code>.tex</code> file and log, guiding the user to fix errors and restart using <code>--start_page</code>.</li>
        <li><strong>Combining Output:</strong> Successfully compiled chunks are progressively added to the main output file.</li>
        <li><strong>Simplified State/Resume:</strong> Uses <code>--start_page</code> for basic resume capability (note: context from before the resume point is not automatically loaded).</li>
        <li><strong>Command-Line Interface:</strong> Uses <code>argparse</code> for required positional arguments (PDF input, TeX output) and optional flags (like <code>--chunk_size</code>, <code>--max_context</code>).</li>
        <li><strong>Logging:</strong> Provides progress updates and error messages.</li>
    </ul>
</div> <!-- End of gemini-explanation div -->

</body>
</html>
